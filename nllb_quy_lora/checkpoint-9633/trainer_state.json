{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 1000,
  "global_step": 9633,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.031144158523766886,
      "grad_norm": 0.46040087938308716,
      "learning_rate": 9.89722827779508e-05,
      "loss": 11.212,
      "step": 100
    },
    {
      "epoch": 0.06228831704753377,
      "grad_norm": 0.5146743655204773,
      "learning_rate": 9.793418457386069e-05,
      "loss": 8.9938,
      "step": 200
    },
    {
      "epoch": 0.09343247557130066,
      "grad_norm": 0.3631499409675598,
      "learning_rate": 9.689608636977059e-05,
      "loss": 7.1136,
      "step": 300
    },
    {
      "epoch": 0.12457663409506754,
      "grad_norm": 0.31076425313949585,
      "learning_rate": 9.585798816568048e-05,
      "loss": 6.4789,
      "step": 400
    },
    {
      "epoch": 0.15572079261883442,
      "grad_norm": 0.23016485571861267,
      "learning_rate": 9.481988996159037e-05,
      "loss": 6.2351,
      "step": 500
    },
    {
      "epoch": 0.18686495114260132,
      "grad_norm": 0.22857621312141418,
      "learning_rate": 9.378179175750026e-05,
      "loss": 6.155,
      "step": 600
    },
    {
      "epoch": 0.2180091096663682,
      "grad_norm": 0.2685433030128479,
      "learning_rate": 9.274369355341015e-05,
      "loss": 6.0688,
      "step": 700
    },
    {
      "epoch": 0.24915326819013509,
      "grad_norm": 0.22749169170856476,
      "learning_rate": 9.170559534932004e-05,
      "loss": 6.0406,
      "step": 800
    },
    {
      "epoch": 0.28029742671390195,
      "grad_norm": 0.24512146413326263,
      "learning_rate": 9.066749714522994e-05,
      "loss": 6.0122,
      "step": 900
    },
    {
      "epoch": 0.31144158523766885,
      "grad_norm": 0.25106820464134216,
      "learning_rate": 8.962939894113984e-05,
      "loss": 5.9607,
      "step": 1000
    },
    {
      "epoch": 0.34258574376143575,
      "grad_norm": 0.2311135232448578,
      "learning_rate": 8.859130073704973e-05,
      "loss": 5.9705,
      "step": 1100
    },
    {
      "epoch": 0.37372990228520264,
      "grad_norm": 0.21516501903533936,
      "learning_rate": 8.755320253295962e-05,
      "loss": 5.9449,
      "step": 1200
    },
    {
      "epoch": 0.40487406080896954,
      "grad_norm": 0.22896374762058258,
      "learning_rate": 8.651510432886951e-05,
      "loss": 5.9059,
      "step": 1300
    },
    {
      "epoch": 0.4360182193327364,
      "grad_norm": 0.23346523940563202,
      "learning_rate": 8.547700612477942e-05,
      "loss": 5.8969,
      "step": 1400
    },
    {
      "epoch": 0.4671623778565033,
      "grad_norm": 0.20979531109333038,
      "learning_rate": 8.443890792068931e-05,
      "loss": 5.9184,
      "step": 1500
    },
    {
      "epoch": 0.49830653638027017,
      "grad_norm": 0.29169097542762756,
      "learning_rate": 8.34008097165992e-05,
      "loss": 5.8933,
      "step": 1600
    },
    {
      "epoch": 0.5294506949040371,
      "grad_norm": 0.24962939321994781,
      "learning_rate": 8.236271151250909e-05,
      "loss": 5.8698,
      "step": 1700
    },
    {
      "epoch": 0.5605948534278039,
      "grad_norm": 0.2525950074195862,
      "learning_rate": 8.132461330841898e-05,
      "loss": 5.8601,
      "step": 1800
    },
    {
      "epoch": 0.5917390119515709,
      "grad_norm": 0.22751973569393158,
      "learning_rate": 8.028651510432887e-05,
      "loss": 5.8469,
      "step": 1900
    },
    {
      "epoch": 0.6228831704753377,
      "grad_norm": 0.25314581394195557,
      "learning_rate": 7.924841690023876e-05,
      "loss": 5.8584,
      "step": 2000
    },
    {
      "epoch": 0.6540273289991047,
      "grad_norm": 0.2558780312538147,
      "learning_rate": 7.821031869614865e-05,
      "loss": 5.8444,
      "step": 2100
    },
    {
      "epoch": 0.6851714875228715,
      "grad_norm": 0.25195205211639404,
      "learning_rate": 7.717222049205856e-05,
      "loss": 5.8292,
      "step": 2200
    },
    {
      "epoch": 0.7163156460466383,
      "grad_norm": 0.26977744698524475,
      "learning_rate": 7.613412228796845e-05,
      "loss": 5.8165,
      "step": 2300
    },
    {
      "epoch": 0.7474598045704053,
      "grad_norm": 0.36176639795303345,
      "learning_rate": 7.509602408387834e-05,
      "loss": 5.81,
      "step": 2400
    },
    {
      "epoch": 0.7786039630941721,
      "grad_norm": 0.3470591902732849,
      "learning_rate": 7.405792587978824e-05,
      "loss": 5.8,
      "step": 2500
    },
    {
      "epoch": 0.8097481216179391,
      "grad_norm": 0.2810184955596924,
      "learning_rate": 7.301982767569813e-05,
      "loss": 5.792,
      "step": 2600
    },
    {
      "epoch": 0.8408922801417059,
      "grad_norm": 0.2583320736885071,
      "learning_rate": 7.198172947160801e-05,
      "loss": 5.7837,
      "step": 2700
    },
    {
      "epoch": 0.8720364386654728,
      "grad_norm": 0.2722410559654236,
      "learning_rate": 7.09436312675179e-05,
      "loss": 5.785,
      "step": 2800
    },
    {
      "epoch": 0.9031805971892397,
      "grad_norm": 0.25979095697402954,
      "learning_rate": 6.99055330634278e-05,
      "loss": 5.7921,
      "step": 2900
    },
    {
      "epoch": 0.9343247557130065,
      "grad_norm": 0.21703234314918518,
      "learning_rate": 6.88674348593377e-05,
      "loss": 5.7798,
      "step": 3000
    },
    {
      "epoch": 0.9654689142367735,
      "grad_norm": 0.24027955532073975,
      "learning_rate": 6.782933665524759e-05,
      "loss": 5.7646,
      "step": 3100
    },
    {
      "epoch": 0.9966130727605403,
      "grad_norm": 0.25935181975364685,
      "learning_rate": 6.679123845115748e-05,
      "loss": 5.7793,
      "step": 3200
    },
    {
      "epoch": 1.0277183010861526,
      "grad_norm": 0.26341116428375244,
      "learning_rate": 6.575314024706738e-05,
      "loss": 5.7857,
      "step": 3300
    },
    {
      "epoch": 1.0588624596099194,
      "grad_norm": 0.2947082817554474,
      "learning_rate": 6.471504204297727e-05,
      "loss": 5.7578,
      "step": 3400
    },
    {
      "epoch": 1.0900066181336863,
      "grad_norm": 0.26339802145957947,
      "learning_rate": 6.367694383888716e-05,
      "loss": 5.7559,
      "step": 3500
    },
    {
      "epoch": 1.121150776657453,
      "grad_norm": 0.31207698583602905,
      "learning_rate": 6.263884563479706e-05,
      "loss": 5.7753,
      "step": 3600
    },
    {
      "epoch": 1.15229493518122,
      "grad_norm": 0.26847949624061584,
      "learning_rate": 6.160074743070695e-05,
      "loss": 5.759,
      "step": 3700
    },
    {
      "epoch": 1.183439093704987,
      "grad_norm": 0.2893042266368866,
      "learning_rate": 6.0562649226616844e-05,
      "loss": 5.7441,
      "step": 3800
    },
    {
      "epoch": 1.2145832522287539,
      "grad_norm": 0.2493840903043747,
      "learning_rate": 5.952455102252673e-05,
      "loss": 5.7548,
      "step": 3900
    },
    {
      "epoch": 1.2457274107525207,
      "grad_norm": 0.2712591588497162,
      "learning_rate": 5.848645281843663e-05,
      "loss": 5.7693,
      "step": 4000
    },
    {
      "epoch": 1.2768715692762878,
      "grad_norm": 0.25458824634552,
      "learning_rate": 5.744835461434652e-05,
      "loss": 5.733,
      "step": 4100
    },
    {
      "epoch": 1.3080157278000546,
      "grad_norm": 0.2658226788043976,
      "learning_rate": 5.6410256410256414e-05,
      "loss": 5.7686,
      "step": 4200
    },
    {
      "epoch": 1.3391598863238214,
      "grad_norm": 0.2985074818134308,
      "learning_rate": 5.5372158206166305e-05,
      "loss": 5.7253,
      "step": 4300
    },
    {
      "epoch": 1.3703040448475883,
      "grad_norm": 0.27034151554107666,
      "learning_rate": 5.43340600020762e-05,
      "loss": 5.7416,
      "step": 4400
    },
    {
      "epoch": 1.4014482033713551,
      "grad_norm": 0.27604207396507263,
      "learning_rate": 5.329596179798609e-05,
      "loss": 5.7113,
      "step": 4500
    },
    {
      "epoch": 1.432592361895122,
      "grad_norm": 0.3098657429218292,
      "learning_rate": 5.2257863593895984e-05,
      "loss": 5.7555,
      "step": 4600
    },
    {
      "epoch": 1.4637365204188888,
      "grad_norm": 0.293518990278244,
      "learning_rate": 5.1219765389805875e-05,
      "loss": 5.7556,
      "step": 4700
    },
    {
      "epoch": 1.4948806789426559,
      "grad_norm": 0.25528308749198914,
      "learning_rate": 5.018166718571577e-05,
      "loss": 5.7568,
      "step": 4800
    },
    {
      "epoch": 1.5260248374664227,
      "grad_norm": 0.2832385003566742,
      "learning_rate": 4.914356898162566e-05,
      "loss": 5.734,
      "step": 4900
    },
    {
      "epoch": 1.5571689959901895,
      "grad_norm": 0.2954837679862976,
      "learning_rate": 4.8105470777535554e-05,
      "loss": 5.7355,
      "step": 5000
    },
    {
      "epoch": 1.5883131545139566,
      "grad_norm": 0.30774179100990295,
      "learning_rate": 4.706737257344545e-05,
      "loss": 5.7592,
      "step": 5100
    },
    {
      "epoch": 1.6194573130377234,
      "grad_norm": 0.2865102291107178,
      "learning_rate": 4.602927436935534e-05,
      "loss": 5.7293,
      "step": 5200
    },
    {
      "epoch": 1.6506014715614903,
      "grad_norm": 0.2581753730773926,
      "learning_rate": 4.4991176165265233e-05,
      "loss": 5.7361,
      "step": 5300
    },
    {
      "epoch": 1.6817456300852571,
      "grad_norm": 0.2926930785179138,
      "learning_rate": 4.395307796117513e-05,
      "loss": 5.7417,
      "step": 5400
    },
    {
      "epoch": 1.712889788609024,
      "grad_norm": 0.3431724011898041,
      "learning_rate": 4.291497975708502e-05,
      "loss": 5.7185,
      "step": 5500
    },
    {
      "epoch": 1.7440339471327908,
      "grad_norm": 0.33350127935409546,
      "learning_rate": 4.187688155299492e-05,
      "loss": 5.715,
      "step": 5600
    },
    {
      "epoch": 1.7751781056565576,
      "grad_norm": 0.27803805470466614,
      "learning_rate": 4.083878334890481e-05,
      "loss": 5.7509,
      "step": 5700
    },
    {
      "epoch": 1.8063222641803247,
      "grad_norm": 0.267642080783844,
      "learning_rate": 3.98006851448147e-05,
      "loss": 5.7544,
      "step": 5800
    },
    {
      "epoch": 1.8374664227040916,
      "grad_norm": 0.3132188022136688,
      "learning_rate": 3.876258694072459e-05,
      "loss": 5.7397,
      "step": 5900
    },
    {
      "epoch": 1.8686105812278586,
      "grad_norm": 0.2695651650428772,
      "learning_rate": 3.772448873663449e-05,
      "loss": 5.6953,
      "step": 6000
    },
    {
      "epoch": 1.8997547397516255,
      "grad_norm": 0.2765352129936218,
      "learning_rate": 3.668639053254438e-05,
      "loss": 5.7348,
      "step": 6100
    },
    {
      "epoch": 1.9308988982753923,
      "grad_norm": 0.2726406753063202,
      "learning_rate": 3.564829232845428e-05,
      "loss": 5.7491,
      "step": 6200
    },
    {
      "epoch": 1.9620430567991591,
      "grad_norm": 1.0570522546768188,
      "learning_rate": 3.461019412436416e-05,
      "loss": 5.742,
      "step": 6300
    },
    {
      "epoch": 1.993187215322926,
      "grad_norm": 0.30487605929374695,
      "learning_rate": 3.357209592027406e-05,
      "loss": 5.7469,
      "step": 6400
    },
    {
      "epoch": 2.0242924436485383,
      "grad_norm": 0.32210463285446167,
      "learning_rate": 3.253399771618395e-05,
      "loss": 5.7235,
      "step": 6500
    },
    {
      "epoch": 2.055436602172305,
      "grad_norm": 0.3011781871318817,
      "learning_rate": 3.149589951209385e-05,
      "loss": 5.6867,
      "step": 6600
    },
    {
      "epoch": 2.086580760696072,
      "grad_norm": 0.3580032289028168,
      "learning_rate": 3.0457801308003736e-05,
      "loss": 5.7238,
      "step": 6700
    },
    {
      "epoch": 2.117724919219839,
      "grad_norm": 0.31403881311416626,
      "learning_rate": 2.9419703103913633e-05,
      "loss": 5.7273,
      "step": 6800
    },
    {
      "epoch": 2.1488690777436057,
      "grad_norm": 0.32101181149482727,
      "learning_rate": 2.8381604899823527e-05,
      "loss": 5.7433,
      "step": 6900
    },
    {
      "epoch": 2.1800132362673725,
      "grad_norm": 0.40054118633270264,
      "learning_rate": 2.7343506695733418e-05,
      "loss": 5.6938,
      "step": 7000
    },
    {
      "epoch": 2.2111573947911394,
      "grad_norm": 0.33352231979370117,
      "learning_rate": 2.6305408491643312e-05,
      "loss": 5.695,
      "step": 7100
    },
    {
      "epoch": 2.242301553314906,
      "grad_norm": 0.30570417642593384,
      "learning_rate": 2.5267310287553203e-05,
      "loss": 5.7427,
      "step": 7200
    },
    {
      "epoch": 2.273445711838673,
      "grad_norm": 0.3454691767692566,
      "learning_rate": 2.4229212083463097e-05,
      "loss": 5.7248,
      "step": 7300
    },
    {
      "epoch": 2.30458987036244,
      "grad_norm": 0.35223275423049927,
      "learning_rate": 2.3191113879372988e-05,
      "loss": 5.6967,
      "step": 7400
    },
    {
      "epoch": 2.335734028886207,
      "grad_norm": 0.3871684968471527,
      "learning_rate": 2.2153015675282882e-05,
      "loss": 5.7052,
      "step": 7500
    },
    {
      "epoch": 2.366878187409974,
      "grad_norm": 0.3180575966835022,
      "learning_rate": 2.1114917471192777e-05,
      "loss": 5.6978,
      "step": 7600
    },
    {
      "epoch": 2.398022345933741,
      "grad_norm": 0.3199875056743622,
      "learning_rate": 2.007681926710267e-05,
      "loss": 5.724,
      "step": 7700
    },
    {
      "epoch": 2.4291665044575077,
      "grad_norm": 0.3054461181163788,
      "learning_rate": 1.9038721063012562e-05,
      "loss": 5.7208,
      "step": 7800
    },
    {
      "epoch": 2.4603106629812745,
      "grad_norm": 0.31117361783981323,
      "learning_rate": 1.8000622858922456e-05,
      "loss": 5.7175,
      "step": 7900
    },
    {
      "epoch": 2.4914548215050414,
      "grad_norm": 0.33750730752944946,
      "learning_rate": 1.696252465483235e-05,
      "loss": 5.7351,
      "step": 8000
    },
    {
      "epoch": 2.5225989800288082,
      "grad_norm": 0.3404191732406616,
      "learning_rate": 1.592442645074224e-05,
      "loss": 5.7288,
      "step": 8100
    },
    {
      "epoch": 2.5537431385525755,
      "grad_norm": 0.30880221724510193,
      "learning_rate": 1.4886328246652133e-05,
      "loss": 5.7457,
      "step": 8200
    },
    {
      "epoch": 2.5848872970763423,
      "grad_norm": 0.7553056478500366,
      "learning_rate": 1.3848230042562028e-05,
      "loss": 5.7373,
      "step": 8300
    },
    {
      "epoch": 2.616031455600109,
      "grad_norm": 0.2831030488014221,
      "learning_rate": 1.281013183847192e-05,
      "loss": 5.7117,
      "step": 8400
    },
    {
      "epoch": 2.647175614123876,
      "grad_norm": 0.25479018688201904,
      "learning_rate": 1.1772033634381813e-05,
      "loss": 5.7191,
      "step": 8500
    },
    {
      "epoch": 2.678319772647643,
      "grad_norm": 0.3009745180606842,
      "learning_rate": 1.0733935430291705e-05,
      "loss": 5.7075,
      "step": 8600
    },
    {
      "epoch": 2.7094639311714097,
      "grad_norm": 0.32928466796875,
      "learning_rate": 9.6958372262016e-06,
      "loss": 5.7295,
      "step": 8700
    },
    {
      "epoch": 2.7406080896951766,
      "grad_norm": 0.3426547944545746,
      "learning_rate": 8.657739022111492e-06,
      "loss": 5.7024,
      "step": 8800
    },
    {
      "epoch": 2.7717522482189434,
      "grad_norm": 0.2904169261455536,
      "learning_rate": 7.619640818021385e-06,
      "loss": 5.7305,
      "step": 8900
    },
    {
      "epoch": 2.8028964067427102,
      "grad_norm": 0.3301334083080292,
      "learning_rate": 6.581542613931278e-06,
      "loss": 5.6842,
      "step": 9000
    },
    {
      "epoch": 2.834040565266477,
      "grad_norm": 0.2988249659538269,
      "learning_rate": 5.543444409841171e-06,
      "loss": 5.7438,
      "step": 9100
    },
    {
      "epoch": 2.865184723790244,
      "grad_norm": 0.32126158475875854,
      "learning_rate": 4.505346205751064e-06,
      "loss": 5.6902,
      "step": 9200
    },
    {
      "epoch": 2.8963288823140108,
      "grad_norm": 0.27186596393585205,
      "learning_rate": 3.4672480016609576e-06,
      "loss": 5.7005,
      "step": 9300
    },
    {
      "epoch": 2.9274730408377776,
      "grad_norm": 0.3270638883113861,
      "learning_rate": 2.4291497975708505e-06,
      "loss": 5.7202,
      "step": 9400
    },
    {
      "epoch": 2.958617199361545,
      "grad_norm": 0.3166320025920868,
      "learning_rate": 1.3910515934807433e-06,
      "loss": 5.7208,
      "step": 9500
    },
    {
      "epoch": 2.9897613578853117,
      "grad_norm": 0.2938804626464844,
      "learning_rate": 3.5295338939063635e-07,
      "loss": 5.7357,
      "step": 9600
    }
  ],
  "logging_steps": 100,
  "max_steps": 9633,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.188903410132582e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
